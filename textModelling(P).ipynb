{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we try to segeragate text according to topic!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('npr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the Washington of 2016, even when the polic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From photography, illustration and video, to d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article\n",
       "0  In the Washington of 2016, even when the polic...\n",
       "1    Donald Trump has used Twitter  —   his prefe...\n",
       "2    Donald Trump is unabashedly praising Russian...\n",
       "3  Updated at 2:50 p. m. ET, Russian President Vl...\n",
       "4  From photography, illustration and video, to d..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Article'][4000]\n",
    "# len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the stopwords!\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['without_stopwords'] = df['Article'].apply(\n",
    "    lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>without_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the Washington of 2016, even when the polic...</td>\n",
       "      <td>In Washington 2016, even policy bipartisan, po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
       "      <td>Donald Trump used Twitter — preferred means co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
       "      <td>Donald Trump unabashedly praising Russian Pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
       "      <td>Updated 2:50 p. m. ET, Russian President Vladi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From photography, illustration and video, to d...</td>\n",
       "      <td>From photography, illustration video, data vis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article  \\\n",
       "0  In the Washington of 2016, even when the polic...   \n",
       "1    Donald Trump has used Twitter  —   his prefe...   \n",
       "2    Donald Trump is unabashedly praising Russian...   \n",
       "3  Updated at 2:50 p. m. ET, Russian President Vl...   \n",
       "4  From photography, illustration and video, to d...   \n",
       "\n",
       "                                   without_stopwords  \n",
       "0  In Washington 2016, even policy bipartisan, po...  \n",
       "1  Donald Trump used Twitter — preferred means co...  \n",
       "2  Donald Trump unabashedly praising Russian Pres...  \n",
       "3  Updated 2:50 p. m. ET, Russian President Vladi...  \n",
       "4  From photography, illustration video, data vis...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_df --> ignore common words across the document!\n",
    "cv = CountVectorizer(max_df=0.9, min_df=2)\n",
    "# min_df --> minimum repeating frequency\n",
    "# stopwords --. remove the stopwords!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = cv.fit_transform(df['without_stopwords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11992x55080 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3549209 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_components=7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=7, random_state=42)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.fit(dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab the vocabulary of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55080"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'baseman'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()[5006]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'practitioner'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the random words!!!\n",
    "import random\n",
    "\n",
    "random_word_id = random.randint(0, 96277)\n",
    "cv.get_feature_names()[random_word_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lda.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lda.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 55080)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.16528422e+01, 5.82490496e+02, 1.42857148e-01, ...,\n",
       "        1.42948137e-01, 1.42857148e-01, 1.42861637e-01],\n",
       "       [5.93571404e+00, 3.62486337e+02, 3.14258498e+00, ...,\n",
       "        6.14250412e+00, 1.25576550e+00, 1.44699194e-01],\n",
       "       [1.86026487e+00, 1.60060850e+03, 1.42857147e-01, ...,\n",
       "        1.42968653e-01, 1.43202940e-01, 1.42857145e-01],\n",
       "       ...,\n",
       "       [2.61447184e+00, 1.72865686e+03, 1.42857149e-01, ...,\n",
       "        1.42894338e-01, 1.42857148e-01, 1.42857146e-01],\n",
       "       [7.40347369e+00, 8.20554094e+02, 1.42881488e-01, ...,\n",
       "        1.42895250e-01, 1.02779288e+00, 1.42881756e-01],\n",
       "       [4.21019613e+01, 1.03455042e+02, 1.43104944e-01, ...,\n",
       "        1.42930378e-01, 1.44667240e-01, 2.14095924e+00]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_topic = lda.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26688, 21819, 20167, ..., 37569, 43192, 42759], dtype=int64)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_topic.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10, 200,   1])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXAMPLE FOR ARGSORT()\n",
    "import numpy as np\n",
    "arr = np.array([10, 200, 1])\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.argsort()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[ 10, 200, 1]\n",
    "[  2,   0, 1]\n",
    "SHOW THE POSITION OF THE LIST!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([41153, 24740, 49866, 26136, 34723, 22729, 36475, 37569, 43192,\n",
       "       42759], dtype=int64)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Argsort --> Returns the positions sorted from the least to greatest\n",
    "# [-10:] --> TOP 10 VALUES (10 GREATEST VALUES)\n",
    "# Last 10 values of the argsort()\n",
    "single_topic.argsort()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ten_words = single_topic.argsort()[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city\n",
      "but\n",
      "npr\n",
      "department\n",
      "court\n",
      "law\n",
      "they\n",
      "two\n",
      "we\n",
      "also\n",
      "reports\n",
      "in\n",
      "told\n",
      "it\n",
      "one\n",
      "he\n",
      "people\n",
      "police\n",
      "says\n",
      "said\n"
     ]
    }
   ],
   "source": [
    "for index in top_ten_words:\n",
    "    print(cv.get_feature_names()[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the higest probability words per topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TOP 15 WORDS FOR THE TOPIC #0\n",
      "['law', 'they', 'two', 'we', 'also', 'reports', 'in', 'told', 'it', 'one', 'he', 'people', 'police', 'says', 'said']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR THE TOPIC #1\n",
      "['also', 'time', 'and', 'years', 'food', 'world', 'but', 'like', 'new', 'first', 'in', 'he', 'one', 'says', 'it']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR THE TOPIC #2\n",
      "['in', 'there', 'get', 're', 'we', 'like', 'and', 'one', 'health', 'that', 'they', 'but', 'people', 'it', 'says']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR THE TOPIC #3\n",
      "['state', 'republican', 'obama', 'election', 'that', 'and', 'but', 'would', 'he', 'it', 'campaign', 'president', 'clinton', 'said', 'trump']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR THE TOPIC #4\n",
      "['new', 'that', 'also', 'care', 'state', 'but', 'government', 'president', 'health', 'people', 'trump', 'it', 'says', 'would', 'said']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR THE TOPIC #5\n",
      "['that', 'but', 'north', 'one', 'said', 'education', 'in', 'schools', 'company', 'china', 'new', 'it', 'school', 'students', 'says']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR THE TOPIC #6\n",
      "['really', 'know', 'he', 'we', 'think', 'but', 're', 'says', 'one', 'people', 'that', 'you', 'like', 'and', 'it']\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, topic in enumerate(lda.components_):\n",
    "    print(f'THE TOP 15 WORDS FOR THE TOPIC #{i}')\n",
    "    print([cv.get_feature_names()[index] for index in topic.argsort()[-15:]])\n",
    "    print('\\n')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_results = lda.transform(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11992, 7)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Topic'] = topic_results.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>without_stopwords</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the Washington of 2016, even when the polic...</td>\n",
       "      <td>In Washington 2016, even policy bipartisan, po...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
       "      <td>Donald Trump used Twitter — preferred means co...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
       "      <td>Donald Trump unabashedly praising Russian Pres...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
       "      <td>Updated 2:50 p. m. ET, Russian President Vladi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From photography, illustration and video, to d...</td>\n",
       "      <td>From photography, illustration video, data vis...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I did not want to join yoga class. I hated tho...</td>\n",
       "      <td>I want join yoga class. I hated beatific instr...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>With a   who has publicly supported the debunk...</td>\n",
       "      <td>With publicly supported debunked claim vaccine...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I was standing by the airport exit, debating w...</td>\n",
       "      <td>I standing airport exit, debating whether get ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>If movies were trying to be more realistic, pe...</td>\n",
       "      <td>If movies trying realistic, perhaps way summon...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Eighteen years ago, on New Year’s Eve, David F...</td>\n",
       "      <td>Eighteen years ago, New Year’s Eve, David Fish...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article  \\\n",
       "0  In the Washington of 2016, even when the polic...   \n",
       "1    Donald Trump has used Twitter  —   his prefe...   \n",
       "2    Donald Trump is unabashedly praising Russian...   \n",
       "3  Updated at 2:50 p. m. ET, Russian President Vl...   \n",
       "4  From photography, illustration and video, to d...   \n",
       "5  I did not want to join yoga class. I hated tho...   \n",
       "6  With a   who has publicly supported the debunk...   \n",
       "7  I was standing by the airport exit, debating w...   \n",
       "8  If movies were trying to be more realistic, pe...   \n",
       "9  Eighteen years ago, on New Year’s Eve, David F...   \n",
       "\n",
       "                                   without_stopwords  Topic  \n",
       "0  In Washington 2016, even policy bipartisan, po...      3  \n",
       "1  Donald Trump used Twitter — preferred means co...      3  \n",
       "2  Donald Trump unabashedly praising Russian Pres...      3  \n",
       "3  Updated 2:50 p. m. ET, Russian President Vladi...      4  \n",
       "4  From photography, illustration video, data vis...      1  \n",
       "5  I want join yoga class. I hated beatific instr...      2  \n",
       "6  With publicly supported debunked claim vaccine...      2  \n",
       "7  I standing airport exit, debating whether get ...      6  \n",
       "8  If movies trying realistic, perhaps way summon...      2  \n",
       "9  Eighteen years ago, New Year’s Eve, David Fish...      1  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
